{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import errno\n",
    "import string\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import itertools\n",
    "from collections import Counter as mset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data cleanning\n",
    "file_list = os.listdir(\"../data/ground_truth\")\n",
    "#create and save error terms in error_list\n",
    "error_df = pd.DataFrame()\n",
    "tess_error_list = list()\n",
    "ground_error_list = list()\n",
    "\n",
    "for file in file_list:\n",
    "    #read ground_truth lines\n",
    "    ground_truth_file_path = \"../data/ground_truth_trimmed/\"+str(file)\n",
    "    ground_truth = open(ground_truth_file_path, \"r\",encoding=\"utf8\")\n",
    "    ground_truth_lines = ground_truth.read().split('\\n')\n",
    "    \n",
    "    #read tesseract lines\n",
    "    tesseract_file_path = \"../data/tesseract/\"+str(file)\n",
    "    tesseract = open(tesseract_file_path, \"r\",encoding=\"utf8\") \n",
    "    tesseract_lines = tesseract.read().split('\\n')\n",
    "    \n",
    "    #print(tesseract_lines)\n",
    "    #print(ground_truth_lines)\n",
    "    \n",
    "    #define function: get words split by space\n",
    "    def get_words(lines):\n",
    "        lines_list = list()\n",
    "        for element in lines:\n",
    "            #element  = element.split(\" \")         \n",
    "            element = [ word for word in element.split(\" \") if not word.isdigit() and word not in string.punctuation]\n",
    "            lines_list.append(element)\n",
    "        return lines_list\n",
    "    \n",
    "    #create documents for tesseract and ground truth\n",
    "    tesseract_doc = get_words(tesseract_lines)\n",
    "    ground_truth_doc = get_words(ground_truth_lines)\n",
    "    \n",
    "    tess_len = len(tesseract_doc)\n",
    "    ground_len = len(ground_truth_doc)\n",
    "    \n",
    "    ###############################################\n",
    "    #######      Check for Mismatch          ######\n",
    "    ###############################################\n",
    "    \n",
    "    ##if tess_len != ground_len:\n",
    "    ##    print(file)\n",
    "    \n",
    "    #####After Trimming 13 mismatched files, no mismatch in number of lines detected\n",
    "    \n",
    "    \n",
    "    \n",
    "    #create and save error terms in error_list\n",
    "    #error_df = pd.DataFrame()\n",
    "    #tess_error_list = list()\n",
    "    #ground_error_list = list()\n",
    "    for i in range(len(tesseract_doc)):\n",
    "        if len(tesseract_doc[i]) == len(ground_truth_doc[i]):\n",
    "            tess = tesseract_doc[i]\n",
    "            ground = ground_truth_doc[i]\n",
    "            for j in range(len(tess)):\n",
    "                #if tess[j] != ground[j]:\n",
    "                    tess_error_list.append(tess[j])\n",
    "                    ground_error_list.append(ground[j])\n",
    "                    \n",
    "error_df['Tesseract'] = tess_error_list\n",
    "error_df['Ground_Truth'] = ground_error_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_detect(word):\n",
    "    #rule_1\n",
    "    rule_1 = len(list(word))>20\n",
    "    \n",
    "    #rule_2\n",
    "    num_punct = len([char for char in word if char in string.punctuation])\n",
    "    num_alpha = len([char for char in word if char.isalpha()])\n",
    "    rule_2 = num_punct>num_alpha\n",
    "    \n",
    "    #rule_3 \n",
    "    rule_3 = len(set([char for char in word[1:-1] if char in string.punctuation]))>=2\n",
    "    \n",
    "    #rule_4\n",
    "    rule_4 = max([len(list(v)) for k,v in itertools.groupby(word)])>=3\n",
    "    \n",
    "    #rule_5\n",
    "    num_upper = len([char for char in word if char.isupper()])\n",
    "    num_lower = len([char for char in word if char.islower()])\n",
    "    rule_5 = num_upper > num_lower and num_upper < len(word)\n",
    "    \n",
    "    #rule_6\n",
    "    if word.isalpha():\n",
    "        vowels = 'aeiouAEIOU'\n",
    "        num_vowels = len([char for char in word if char in vowels])\n",
    "        num_consonants = len(word) - num_vowels       \n",
    "        rule_6 = num_vowels > 8*num_consonants or num_consonants > 8*num_vowels\n",
    "    else : rule_6 = False\n",
    "    \n",
    "    #rule_7\n",
    "    try:\n",
    "        vowels_len = max([len(w) for w in re.findall(r'[aeiou]+',word,re.IGNORECASE)])\n",
    "    except ValueError:\n",
    "        vowels_len = 0 \n",
    "    try:\n",
    "        conson_len = max([len(w) for w in re.findall(r'[^aeiou]+',word,re.IGNORECASE)])\n",
    "    except ValueError:\n",
    "        conson_len = 0      \n",
    "    rule_7 = vowels_len>=4 or conson_len >=5\n",
    "    \n",
    "    #rule_8\n",
    "    rule_8 = word[0].islower() and word[-1].islower() and word[1:-1].isupper()\n",
    "\n",
    "    return rule_1 or rule_2 or rule_3 or rule_4 or rule_5 or rule_6 or rule_7 or rule_8\n",
    "\n",
    "#######Detect Error #######\n",
    "error_df.insert(loc =2, column=\"IS_error\", value= error_df.Tesseract.map(error_detect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc_digit(string):\n",
    "    string = re.sub(r'[^\\w\\s]','',string)\n",
    "    string = re.sub(r'[^\\D]','',string)\n",
    "    return string\n",
    "\n",
    "error_df['Tesseract'] = error_df['Tesseract'].apply(lambda x: remove_punc_digit(x))\n",
    "error_df['Ground_Truth'] = error_df['Ground_Truth'].apply(lambda x: remove_punc_digit(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error ground truth pairs\n",
    "error_df = error_df[error_df.IS_error==True]\n",
    "error_df = error_df.drop(columns=\"IS_error\")\n",
    "error_df.Tesseract.replace('', np.nan, inplace=True)\n",
    "error_df.Ground_Truth.replace('', np.nan, inplace=True)\n",
    "error_df = error_df.dropna()\n",
    "error_df = error_df.reset_index(drop = True)\n",
    "error_df.to_csv(\"../output/Error_df_rules_based.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = []\n",
    "path = '../data/ground_truth/*.txt'\n",
    "files = glob.glob(path)\n",
    "for name in files:\n",
    "    try:\n",
    "        with open(name, encoding='utf8') as f:\n",
    "            for line in f:\n",
    "                out = line.translate(str.maketrans('', '', string.punctuation))\n",
    "                out = ''.join([i for i in out if not i.isdigit()])\n",
    "                out = out.lower().split()\n",
    "                truth.extend(out)\n",
    "    except IOError as exc:\n",
    "        if exc.errno != errno.EISDIR:\n",
    "            raise\n",
    "np.savetxt('../output/truth_corpus.dat', truth, fmt='%s', encoding='utf8')\n",
    "\n",
    "tess = []\n",
    "path = '../data/tesseract/*.txt'\n",
    "files = glob.glob(path)\n",
    "for name in files:\n",
    "    try:\n",
    "        with open(name, encoding='utf8') as f:\n",
    "            for line in f:\n",
    "                out = line.translate(str.maketrans('', '', string.punctuation))\n",
    "                out = ''.join([i for i in out if not i.isdigit()])\n",
    "                out = out.lower().split()\n",
    "                tess.extend(out)\n",
    "    except IOError as exc:\n",
    "        if exc.errno != errno.EISDIR:\n",
    "            raise\n",
    "np.savetxt('../output/tess_corpus.dat', tess, fmt='%s', encoding='utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading data for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Error = []\n",
    "Truth = []\n",
    "pair = []\n",
    "with open('../output/Error_df_rules_based.csv', encoding='utf8') as f:\n",
    "    csv_reader = csv.reader(f, delimiter=',')\n",
    "    for row in csv_reader:\n",
    "        err = row[1].lower()\n",
    "        trt = row[2].lower()\n",
    "        if err != trt and [err, trt] not in pair:\n",
    "            Error.append(err)\n",
    "            Truth.append(trt)\n",
    "            pair.append([err, trt])\n",
    "            \n",
    "Error = Error[2:]\n",
    "Truth = Truth[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../lib\")\n",
    "from feature_scoring import n_gram\n",
    "from feature_scoring import candidate_search\n",
    "from feature_scoring import LED_score\n",
    "from feature_scoring import SS_score\n",
    "from feature_scoring import LP_score\n",
    "from feature_scoring import ECP_score\n",
    "from feature_scoring import RCP_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_error=['Typo']\n",
    "W_truth=['Truth']\n",
    "W_cand = ['Candidate']\n",
    "Label = ['Label']\n",
    "LED = ['led_score']\n",
    "SS = ['ss_score']\n",
    "LP = ['lp_score']\n",
    "ECP = ['ECP_score']\n",
    "\n",
    "n = 3 # n_gram\n",
    "for i in range(len(Error)):\n",
    "    w_e = Error[i]\n",
    "    w_c = Truth[i]\n",
    "    cand_list = candidate_search(truth, w_e)\n",
    "    print('word ',i+1,', error: ', w_e, ', truth: ', w_c)\n",
    "    \n",
    "#    gram_list = n_gram(w_e, tess, n)\n",
    "    LP_freq = []\n",
    "#    ECP_freq = []\n",
    "    for s in cand_list:\n",
    "        lp_freq = LP_score(s, truth)\n",
    "        LP_freq.append(lp_freq)\n",
    "#        ecp_freq = ECP_score(gram_list, s, truth, n)\n",
    "#       ECP_freq.append(ecp_freq)\n",
    "        \n",
    "    for j in range(len(cand_list)):\n",
    "        s = cand_list[j]\n",
    "        led = LED_score(w_e, s)\n",
    "        ss = SS_score(w_e, s, N=3)\n",
    "        lp = LP_score(s, truth)/max(LP_freq)\n",
    "#        if max(ECP_freq)==0: ecp=0\n",
    "#        else: ecp = ECP_score(gram_list, s, truth, n)/max(ECP_freq)\n",
    "#        rcp = RCP_score(w_e, s, tess, truth)\n",
    "        label = int(s == w_c)\n",
    "#        print('candidate:', s, '\\tscores =', '{:03.2f}'.format(led),', {:03.2f}'.format(ss),', {:06.5f}'.format(lp), '\\tlabel=', label)\n",
    "        W_error.append(w_e)\n",
    "        W_truth.append(w_c)\n",
    "        W_cand.append(s)\n",
    "        Label.append(label)\n",
    "        LED.append(led)\n",
    "        SS.append(ss)\n",
    "        LP.append(lp)\n",
    "        #ECP.append(ecp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('../output/feature.csv', [p for p in zip(W_error, W_truth, W_cand, LED, SS, LP, Label)], delimiter=',', fmt='%s', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retreive Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_output = pd.read_csv('../output/feature.csv', delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Typo</th>\n",
       "      <th>Truth</th>\n",
       "      <th>Candidate</th>\n",
       "      <th>led_score</th>\n",
       "      <th>ss_score</th>\n",
       "      <th>lp_score</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>willlam</td>\n",
       "      <td>william</td>\n",
       "      <td>will</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.636364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>willlam</td>\n",
       "      <td>william</td>\n",
       "      <td>willful</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.607143</td>\n",
       "      <td>0.001712</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>willlam</td>\n",
       "      <td>william</td>\n",
       "      <td>william</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>0.039954</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>willlam</td>\n",
       "      <td>william</td>\n",
       "      <td>williams</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.866667</td>\n",
       "      <td>0.003995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>willlam</td>\n",
       "      <td>william</td>\n",
       "      <td>willing</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>0.006849</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>willlam</td>\n",
       "      <td>william</td>\n",
       "      <td>wills</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000571</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nvolvng</td>\n",
       "      <td>involving</td>\n",
       "      <td>cooling</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nvolvng</td>\n",
       "      <td>involving</td>\n",
       "      <td>evolve</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.045977</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nvolvng</td>\n",
       "      <td>involving</td>\n",
       "      <td>evolved</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nvolvng</td>\n",
       "      <td>involving</td>\n",
       "      <td>evolves</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nvolvng</td>\n",
       "      <td>involving</td>\n",
       "      <td>evolving</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.633333</td>\n",
       "      <td>0.057471</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>nvolvng</td>\n",
       "      <td>involving</td>\n",
       "      <td>involvad</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>nvolvng</td>\n",
       "      <td>involving</td>\n",
       "      <td>involve</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.126437</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>nvolvng</td>\n",
       "      <td>involving</td>\n",
       "      <td>involved</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>nvolvng</td>\n",
       "      <td>involving</td>\n",
       "      <td>involves</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.160920</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>nvolvng</td>\n",
       "      <td>involving</td>\n",
       "      <td>involve­</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>nvolvng</td>\n",
       "      <td>involving</td>\n",
       "      <td>involving</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.656250</td>\n",
       "      <td>0.505747</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>nvolvng</td>\n",
       "      <td>involving</td>\n",
       "      <td>lnvolva</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>nvolvng</td>\n",
       "      <td>involving</td>\n",
       "      <td>noting</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.057471</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>nvolvng</td>\n",
       "      <td>involving</td>\n",
       "      <td>solving</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.035714</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Typo      Truth  Candidate  led_score  ss_score  lp_score  Label\n",
       "0   willlam    william       will       0.25  1.636364  1.000000      0\n",
       "1   willlam    william    willful       0.25  1.607143  0.001712      0\n",
       "2   willlam    william    william       0.75  2.142857  0.039954      1\n",
       "3   willlam    william   williams       0.50  1.866667  0.003995      0\n",
       "4   willlam    william    willing       0.25  1.285714  0.006849      0\n",
       "5   willlam    william      wills       0.25  1.500000  0.000571      0\n",
       "6   nvolvng  involving    cooling       0.25  0.857143  0.011494      0\n",
       "7   nvolvng  involving     evolve       0.25  0.961538  0.045977      0\n",
       "8   nvolvng  involving    evolved       0.25  0.892857  0.034483      0\n",
       "9   nvolvng  involving    evolves       0.25  0.892857  0.011494      0\n",
       "10  nvolvng  involving   evolving       0.50  1.633333  0.057471      0\n",
       "11  nvolvng  involving   involvad       0.25  0.833333  0.011494      0\n",
       "12  nvolvng  involving    involve       0.25  0.892857  0.126437      0\n",
       "13  nvolvng  involving   involved       0.25  0.833333  1.000000      0\n",
       "14  nvolvng  involving   involves       0.25  0.833333  0.160920      0\n",
       "15  nvolvng  involving   involve­       0.25  0.833333  0.011494      0\n",
       "16  nvolvng  involving  involving       0.50  1.656250  0.505747      1\n",
       "17  nvolvng  involving    lnvolva       0.25  0.892857  0.011494      0\n",
       "18  nvolvng  involving     noting       0.25  0.807692  0.057471      0\n",
       "19  nvolvng  involving    solving       0.25  1.035714  0.022989      0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_output.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = feature_output[feature_output.columns[0:6]]\n",
    "y = feature_output[\"Label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train & Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "group = pd.Categorical(feature_output[\"Typo\"])\n",
    "train_inds, test_inds = next(GroupShuffleSplit(random_state=42).split(X, y, group))\n",
    "X_train, X_test, y_train, y_test = X.iloc[list(train_inds)], X.iloc[list(test_inds)], y.iloc[list(train_inds)], y.iloc[list(test_inds)]\n",
    "train_words = X_train[X_train.columns[0:3]]\n",
    "test_words = X_test[X_test.columns[0:3]]\n",
    "X_train = X_train[X_train.columns[3:6]]\n",
    "X_test = X_test[X_test.columns[3:6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1238133, 3) \n",
      " y_train shape: (1238133,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape:',X_train.shape,'\\n','y_train shape:',y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape: (165302, 3) \n",
      " y_test shape: (165302,)\n"
     ]
    }
   ],
   "source": [
    "print('X_test shape:',X_test.shape,'\\n','y_test shape:',y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AdaBoostRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    " 'n_estimators': [50, 100],\n",
    " 'learning_rate' : [0.01,0.05,0.1,0.3,1],\n",
    " 'loss' : ['linear', 'square', 'exponential']\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 2520.1292009353638\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "ada_grid_search = GridSearchCV(model,parameters,cv = 3,n_jobs =-1)\n",
    "ada_grid_search_fit = ada_grid_search.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print('Time:',end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.01, 'loss': 'exponential', 'n_estimators': 50}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_grid_search_fit.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='exponential',\n",
       "         n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_grid_search_fit.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = ada_grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40374915824108776 {'learning_rate': 0.01, 'loss': 'linear', 'n_estimators': 50}\n",
      "0.3680232694914383 {'learning_rate': 0.01, 'loss': 'linear', 'n_estimators': 100}\n",
      "0.4023762621878514 {'learning_rate': 0.01, 'loss': 'square', 'n_estimators': 50}\n",
      "0.34098242730811906 {'learning_rate': 0.01, 'loss': 'square', 'n_estimators': 100}\n",
      "0.4083847633391772 {'learning_rate': 0.01, 'loss': 'exponential', 'n_estimators': 50}\n",
      "0.39643609293192866 {'learning_rate': 0.01, 'loss': 'exponential', 'n_estimators': 100}\n",
      "0.15414374962757887 {'learning_rate': 0.05, 'loss': 'linear', 'n_estimators': 50}\n",
      "-0.23349487386235154 {'learning_rate': 0.05, 'loss': 'linear', 'n_estimators': 100}\n",
      "-0.10284196383632471 {'learning_rate': 0.05, 'loss': 'square', 'n_estimators': 50}\n",
      "-0.9978515475452031 {'learning_rate': 0.05, 'loss': 'square', 'n_estimators': 100}\n",
      "0.27868712935106005 {'learning_rate': 0.05, 'loss': 'exponential', 'n_estimators': 50}\n",
      "-0.05210748438201115 {'learning_rate': 0.05, 'loss': 'exponential', 'n_estimators': 100}\n",
      "-0.18220429066384375 {'learning_rate': 0.1, 'loss': 'linear', 'n_estimators': 50}\n",
      "-0.3433878616741871 {'learning_rate': 0.1, 'loss': 'linear', 'n_estimators': 100}\n",
      "-0.9308229281848934 {'learning_rate': 0.1, 'loss': 'square', 'n_estimators': 50}\n",
      "-1.0131045582770672 {'learning_rate': 0.1, 'loss': 'square', 'n_estimators': 100}\n",
      "-0.06313284282744469 {'learning_rate': 0.1, 'loss': 'exponential', 'n_estimators': 50}\n",
      "-0.7592209661142575 {'learning_rate': 0.1, 'loss': 'exponential', 'n_estimators': 100}\n",
      "-0.31279929981489774 {'learning_rate': 0.3, 'loss': 'linear', 'n_estimators': 50}\n",
      "-0.37670143401303086 {'learning_rate': 0.3, 'loss': 'linear', 'n_estimators': 100}\n",
      "-1.0867650054545688 {'learning_rate': 0.3, 'loss': 'square', 'n_estimators': 50}\n",
      "-0.976816075191342 {'learning_rate': 0.3, 'loss': 'square', 'n_estimators': 100}\n",
      "-1.0901767341119117 {'learning_rate': 0.3, 'loss': 'exponential', 'n_estimators': 50}\n",
      "-1.5741717968173896 {'learning_rate': 0.3, 'loss': 'exponential', 'n_estimators': 100}\n",
      "0.37608463662658714 {'learning_rate': 1, 'loss': 'linear', 'n_estimators': 50}\n",
      "0.38336523445017 {'learning_rate': 1, 'loss': 'linear', 'n_estimators': 100}\n",
      "0.38065389767817553 {'learning_rate': 1, 'loss': 'square', 'n_estimators': 50}\n",
      "0.38312320725422755 {'learning_rate': 1, 'loss': 'square', 'n_estimators': 100}\n",
      "-0.574025360829864 {'learning_rate': 1, 'loss': 'exponential', 'n_estimators': 50}\n",
      "-0.4591920761561897 {'learning_rate': 1, 'loss': 'exponential', 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]): \n",
    "    print(mean_score, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 45.84798288345337\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "regessor = AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='exponential',\n",
    "         n_estimators=50, random_state=None)\n",
    "regessor_fit = regessor.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print('Time:',end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = regessor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_confidence = pd.DataFrame({\"predicted_confidence\": result})\n",
    "test_typo =  pd.DataFrame({\"typo\": np.array(test_words['Typo'])})\n",
    "test_truth = pd.DataFrame({\"truth\": np.array(test_words['Truth'])})\n",
    "test_candidate = pd.DataFrame({\"candidate\": np.array(test_words['Candidate'])})\n",
    "label = pd.DataFrame({\"label\": np.array(y_test)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsorted_test_final_output = pd.concat([test_typo, test_truth, test_candidate, predicted_confidence, label], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define files path\n",
    "tess_dir = \"../data/tesseract/\"\n",
    "ground_dir = \"../data/ground_truth_trimmed/\"\n",
    "file_name = os.listdir(tess_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "373.4526343799894"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Avreage Number of Candidates \n",
    "feature_output.shape[0]/feature_output[feature_output.Label==1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top_n candidates\n",
    "candidate_10 = unsorted_test_final_output.groupby(\"typo\").apply(lambda x: x.nlargest(10,columns = 'predicted_confidence'))\n",
    "candidate_5 = unsorted_test_final_output.groupby(\"typo\").apply(lambda x: x.nlargest(5,columns = 'predicted_confidence'))\n",
    "candidate_3 = unsorted_test_final_output.groupby(\"typo\").apply(lambda x: x.nlargest(3,columns = 'predicted_confidence'))\n",
    "candidate_1 = unsorted_test_final_output.groupby(\"typo\").apply(lambda x: x.nlargest(1,columns = 'predicted_confidence'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>typo</th>\n",
       "      <th>truth</th>\n",
       "      <th>candidate</th>\n",
       "      <th>predicted_confidence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>141602</th>\n",
       "      <td>acrsv</td>\n",
       "      <td>acrs</td>\n",
       "      <td>acrs</td>\n",
       "      <td>0.395005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141598</th>\n",
       "      <td>acrsv</td>\n",
       "      <td>acrs</td>\n",
       "      <td>acr</td>\n",
       "      <td>0.077035</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141601</th>\n",
       "      <td>acrsv</td>\n",
       "      <td>acrs</td>\n",
       "      <td>across</td>\n",
       "      <td>0.077035</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141599</th>\n",
       "      <td>acrsv</td>\n",
       "      <td>acrs</td>\n",
       "      <td>acra</td>\n",
       "      <td>0.030645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141600</th>\n",
       "      <td>acrsv</td>\n",
       "      <td>acrs</td>\n",
       "      <td>acre</td>\n",
       "      <td>0.030645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141603</th>\n",
       "      <td>acrsv</td>\n",
       "      <td>acrs</td>\n",
       "      <td>acs</td>\n",
       "      <td>0.023050</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141604</th>\n",
       "      <td>acrsv</td>\n",
       "      <td>acrs</td>\n",
       "      <td>acsh</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141608</th>\n",
       "      <td>acrsv</td>\n",
       "      <td>acrs</td>\n",
       "      <td>activ</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141611</th>\n",
       "      <td>acrsv</td>\n",
       "      <td>acrs</td>\n",
       "      <td>acts</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141679</th>\n",
       "      <td>acrsv</td>\n",
       "      <td>acrs</td>\n",
       "      <td>cars</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         typo truth candidate  predicted_confidence  label\n",
       "141602  acrsv  acrs      acrs              0.395005      1\n",
       "141598  acrsv  acrs       acr              0.077035      0\n",
       "141601  acrsv  acrs    across              0.077035      0\n",
       "141599  acrsv  acrs      acra              0.030645      0\n",
       "141600  acrsv  acrs      acre              0.030645      0\n",
       "141603  acrsv  acrs       acs              0.023050      0\n",
       "141604  acrsv  acrs      acsh              0.000898      0\n",
       "141608  acrsv  acrs     activ              0.000898      0\n",
       "141611  acrsv  acrs      acts              0.000898      0\n",
       "141679  acrsv  acrs      cars              0.000898      0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_10.loc['acrsv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>71.55%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>86.74%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>88.95%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>91.85%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   top precision\n",
       "0    1    71.55%\n",
       "1    3    86.74%\n",
       "2    5    88.95%\n",
       "3   10    91.85%"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Top_n candidates wordwise precision\n",
    "total_typo = sum(y_test==1)\n",
    "top_10= \"{0:.2%}\".format(candidate_10[candidate_10.label==1].shape[0]/total_typo)\n",
    "top_5= \"{0:.2%}\".format(candidate_5[candidate_5.label==1].shape[0]/total_typo)\n",
    "top_3= \"{0:.2%}\".format(candidate_3[candidate_3.label==1].shape[0]/total_typo)\n",
    "top_1= \"{0:.2%}\".format(candidate_1[candidate_1.label==1].shape[0]/total_typo)\n",
    "\n",
    "top = pd.DataFrame({\"top\": np.array([1,3,5,10])})\n",
    "precision = pd.DataFrame({\"precision\": np.array([top_1, top_3, top_5, top_10])})\n",
    "pd.concat([top, precision], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = regessor.predict(X[X.columns[3:6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_confidence = pd.DataFrame({\"predicted_confidence\": pred})\n",
    "test_typo =  pd.DataFrame({\"typo\": X['Typo']})\n",
    "test_truth = pd.DataFrame({\"truth\": X['Truth']})\n",
    "test_candidate = pd.DataFrame({\"candidate\": X['Candidate']})\n",
    "label = pd.DataFrame({\"label\": y})\n",
    "unsorted_test_final_output = pd.concat([test_typo, test_truth, test_candidate, predicted_confidence, label], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_1 = unsorted_test_final_output.groupby(\"typo\").apply(lambda x: x.nlargest(1,columns = 'predicted_confidence'))\n",
    "cand = candidate_1.candidate.values\n",
    "typo = candidate_1.typo.values\n",
    "cand_dict = dict(zip(typo, cand))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tess = []\n",
    "for s in tess:\n",
    "    if s in cand_dict:\n",
    "        new_tess.append(cand_dict[s])\n",
    "    else:\n",
    "        new_tess.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_tess = \" \".join(tess)\n",
    "char_new_tess = \" \".join(new_tess)\n",
    "char_truth = \" \".join(truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insect(sa,sb):\n",
    "    S_a = set(sa)\n",
    "    n=0\n",
    "    for s in S_a:\n",
    "        n += min(sa.count(s), sb.count(s))\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_word = insect(tess, truth)\n",
    "new_word = insect(new_tess, truth)\n",
    "old_char = insect(char_tess, char_truth)\n",
    "new_char = insect(char_new_tess, char_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Measure</th>\n",
       "      <th>Tesseract</th>\n",
       "      <th>Post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>word_wise_recall</td>\n",
       "      <td>0.645514</td>\n",
       "      <td>0.737668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>word_wise_precision</td>\n",
       "      <td>0.651473</td>\n",
       "      <td>0.744477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>character_wise_recall</td>\n",
       "      <td>0.921204</td>\n",
       "      <td>0.941688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>character_wise_precision</td>\n",
       "      <td>0.950425</td>\n",
       "      <td>0.969093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Measure  Tesseract      Post\n",
       "0          word_wise_recall   0.645514  0.737668\n",
       "1       word_wise_precision   0.651473  0.744477\n",
       "2     character_wise_recall   0.921204  0.941688\n",
       "3  character_wise_precision   0.950425  0.969093"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_word_tess = old_word/len(truth)\n",
    "precision_word_tess = old_word/len(tess)\n",
    "recall_word_post = new_word/len(truth)\n",
    "precision_word_post = new_word/len(new_tess)\n",
    "\n",
    "recall_char_tess = old_char/len(char_truth)\n",
    "precision_char_tess = old_char/len(char_tess)\n",
    "recall_char_post = new_char/len(char_truth)\n",
    "precision_char_post = new_char/len(char_new_tess)\n",
    "\n",
    "Measure = pd.DataFrame({\"Measure\": np.array(['word_wise_recall','word_wise_precision','character_wise_recall','character_wise_precision'])})\n",
    "Tesseract = pd.DataFrame({\"Tesseract\": np.array([recall_word_tess, precision_word_tess, recall_char_tess, precision_char_tess])})\n",
    "PostProcessing = pd.DataFrame({\"Post\": np.array([recall_word_post, precision_word_post, recall_char_post, precision_char_post])})\n",
    "pd.concat([Measure, Tesseract, PostProcessing], axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
