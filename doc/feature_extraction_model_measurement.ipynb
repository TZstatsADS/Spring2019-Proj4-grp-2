{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import errno\n",
    "import string\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from collections import Counter as mset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = []\n",
    "path = '../data/ground_truth/*.txt'\n",
    "files = glob.glob(path)\n",
    "for name in files:\n",
    "    try:\n",
    "        with open(name, encoding='utf8') as f:\n",
    "            for line in f:\n",
    "                out = line.translate(str.maketrans('', '', string.punctuation))\n",
    "                out = ''.join([i for i in out if not i.isdigit()])\n",
    "                out = out.lower().split()\n",
    "                truth.extend(out)\n",
    "    except IOError as exc:\n",
    "        if exc.errno != errno.EISDIR:\n",
    "            raise\n",
    "np.savetxt('../output/truth_corpus.dat', truth, fmt='%s', encoding='utf8')\n",
    "\n",
    "tess = []\n",
    "path = '../data/tesseract/*.txt'\n",
    "files = glob.glob(path)\n",
    "for name in files:\n",
    "    try:\n",
    "        with open(name, encoding='utf8') as f:\n",
    "            for line in f:\n",
    "                out = line.translate(str.maketrans('', '', string.punctuation))\n",
    "                out = ''.join([i for i in out if not i.isdigit()])\n",
    "                out = out.lower().split()\n",
    "                tess.extend(out)\n",
    "    except IOError as exc:\n",
    "        if exc.errno != errno.EISDIR:\n",
    "            raise\n",
    "np.savetxt('../output/tess_corpus.dat', tess, fmt='%s', encoding='utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading data for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Error = []\n",
    "Truth = []\n",
    "pair = []\n",
    "with open('../data/Error_df_rules_based.csv', encoding='utf8') as f:\n",
    "    csv_reader = csv.reader(f, delimiter=',')\n",
    "    for row in csv_reader:\n",
    "        err = row[1].lower()\n",
    "        trt = row[2].lower()\n",
    "        if err != trt and [err, trt] not in pair:\n",
    "            Error.append(err)\n",
    "            Truth.append(trt)\n",
    "            pair.append([err, trt])\n",
    "            \n",
    "Error = Error[2:]\n",
    "Truth = Truth[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../lib\")\n",
    "from feature_scoring import n_gram\n",
    "from feature_scoring import candidate_search\n",
    "from feature_scoring import LED_score\n",
    "from feature_scoring import SS_score\n",
    "from feature_scoring import LP_score\n",
    "from feature_scoring import ECP_score\n",
    "from feature_scoring import RCP_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_error=['Typo']\n",
    "W_truth=['Truth']\n",
    "W_cand = ['Candidate']\n",
    "Label = ['Label']\n",
    "LED = ['led_score']\n",
    "SS = ['ss_score']\n",
    "LP = ['lp_score']\n",
    "ECP = ['ECP_score']\n",
    "\n",
    "n = 3 # n_gram\n",
    "for i in range(len(Error)):\n",
    "    w_e = Error[i]\n",
    "    w_c = Truth[i]\n",
    "    cand_list = candidate_search(truth, w_e)\n",
    "    print('word ',i+1,', error: ', w_e, ', truth: ', w_c)\n",
    "    \n",
    "#    gram_list = n_gram(w_e, tess, n)\n",
    "    LP_freq = []\n",
    "#    ECP_freq = []\n",
    "    for s in cand_list:\n",
    "        lp_freq = LP_score(s, truth)\n",
    "        LP_freq.append(lp_freq)\n",
    "#        ecp_freq = ECP_score(gram_list, s, truth, n)\n",
    "#       ECP_freq.append(ecp_freq)\n",
    "        \n",
    "    for j in range(len(cand_list)):\n",
    "        s = cand_list[j]\n",
    "        led = LED_score(w_e, s)\n",
    "        ss = SS_score(w_e, s, N=3)\n",
    "        lp = LP_score(s, truth)/max(LP_freq)\n",
    "#        if max(ECP_freq)==0: ecp=0\n",
    "#        else: ecp = ECP_score(gram_list, s, truth, n)/max(ECP_freq)\n",
    "#        rcp = RCP_score(w_e, s, tess, truth)\n",
    "        label = int(s == w_c)\n",
    "#        print('candidate:', s, '\\tscores =', '{:03.2f}'.format(led),', {:03.2f}'.format(ss),', {:06.5f}'.format(lp), '\\tlabel=', label)\n",
    "        W_error.append(w_e)\n",
    "        W_truth.append(w_c)\n",
    "        W_cand.append(s)\n",
    "        Label.append(label)\n",
    "        LED.append(led)\n",
    "        SS.append(ss)\n",
    "        LP.append(lp)\n",
    "        #ECP.append(ecp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('../output/feature.csv', [p for p in zip(W_error, W_truth, W_cand, LED, SS, LP, Label)], delimiter=',', fmt='%s', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retreive Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_output = pd.read_csv('../output/feature.csv', delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Typo</th>\n",
       "      <th>Truth</th>\n",
       "      <th>Candidate</th>\n",
       "      <th>led_score</th>\n",
       "      <th>ss_score</th>\n",
       "      <th>lp_score</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>willlam</td>\n",
       "      <td>william</td>\n",
       "      <td>will</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.636364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>willlam</td>\n",
       "      <td>william</td>\n",
       "      <td>willful</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.607143</td>\n",
       "      <td>0.001712</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>willlam</td>\n",
       "      <td>william</td>\n",
       "      <td>william</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>0.039954</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>willlam</td>\n",
       "      <td>william</td>\n",
       "      <td>williams</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.866667</td>\n",
       "      <td>0.003995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>willlam</td>\n",
       "      <td>william</td>\n",
       "      <td>willing</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>0.006849</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>willlam</td>\n",
       "      <td>william</td>\n",
       "      <td>wills</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000571</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nvolvng</td>\n",
       "      <td>involving</td>\n",
       "      <td>cooling</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nvolvng</td>\n",
       "      <td>involving</td>\n",
       "      <td>evolve</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.045977</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nvolvng</td>\n",
       "      <td>involving</td>\n",
       "      <td>evolved</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nvolvng</td>\n",
       "      <td>involving</td>\n",
       "      <td>evolves</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nvolvng</td>\n",
       "      <td>involving</td>\n",
       "      <td>evolving</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.633333</td>\n",
       "      <td>0.057471</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>nvolvng</td>\n",
       "      <td>involving</td>\n",
       "      <td>involvad</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>nvolvng</td>\n",
       "      <td>involving</td>\n",
       "      <td>involve</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.126437</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>nvolvng</td>\n",
       "      <td>involving</td>\n",
       "      <td>involved</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>nvolvng</td>\n",
       "      <td>involving</td>\n",
       "      <td>involves</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.160920</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>nvolvng</td>\n",
       "      <td>involving</td>\n",
       "      <td>involve­</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>nvolvng</td>\n",
       "      <td>involving</td>\n",
       "      <td>involving</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.656250</td>\n",
       "      <td>0.505747</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>nvolvng</td>\n",
       "      <td>involving</td>\n",
       "      <td>lnvolva</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>nvolvng</td>\n",
       "      <td>involving</td>\n",
       "      <td>noting</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.057471</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>nvolvng</td>\n",
       "      <td>involving</td>\n",
       "      <td>solving</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.035714</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Typo      Truth  Candidate  led_score  ss_score  lp_score  Label\n",
       "0   willlam    william       will       0.25  1.636364  1.000000      0\n",
       "1   willlam    william    willful       0.25  1.607143  0.001712      0\n",
       "2   willlam    william    william       0.75  2.142857  0.039954      1\n",
       "3   willlam    william   williams       0.50  1.866667  0.003995      0\n",
       "4   willlam    william    willing       0.25  1.285714  0.006849      0\n",
       "5   willlam    william      wills       0.25  1.500000  0.000571      0\n",
       "6   nvolvng  involving    cooling       0.25  0.857143  0.011494      0\n",
       "7   nvolvng  involving     evolve       0.25  0.961538  0.045977      0\n",
       "8   nvolvng  involving    evolved       0.25  0.892857  0.034483      0\n",
       "9   nvolvng  involving    evolves       0.25  0.892857  0.011494      0\n",
       "10  nvolvng  involving   evolving       0.50  1.633333  0.057471      0\n",
       "11  nvolvng  involving   involvad       0.25  0.833333  0.011494      0\n",
       "12  nvolvng  involving    involve       0.25  0.892857  0.126437      0\n",
       "13  nvolvng  involving   involved       0.25  0.833333  1.000000      0\n",
       "14  nvolvng  involving   involves       0.25  0.833333  0.160920      0\n",
       "15  nvolvng  involving   involve­       0.25  0.833333  0.011494      0\n",
       "16  nvolvng  involving  involving       0.50  1.656250  0.505747      1\n",
       "17  nvolvng  involving    lnvolva       0.25  0.892857  0.011494      0\n",
       "18  nvolvng  involving     noting       0.25  0.807692  0.057471      0\n",
       "19  nvolvng  involving    solving       0.25  1.035714  0.022989      0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_output.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = feature_output[feature_output.columns[0:6]]\n",
    "y = feature_output[\"Label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train & Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "group = pd.Categorical(feature_output[\"Typo\"])\n",
    "train_inds, test_inds = next(GroupShuffleSplit(random_state=42).split(X, y, group))\n",
    "X_train, X_test, y_train, y_test = X.iloc[list(train_inds)], X.iloc[list(test_inds)], y.iloc[list(train_inds)], y.iloc[list(test_inds)]\n",
    "train_words = X_train[X_train.columns[0:3]]\n",
    "test_words = X_test[X_test.columns[0:3]]\n",
    "X_train = X_train[X_train.columns[3:6]]\n",
    "X_test = X_test[X_test.columns[3:6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1238133, 3) \n",
      " y_train shape: (1238133,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape:',X_train.shape,'\\n','y_train shape:',y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape: (165302, 3) \n",
      " y_test shape: (165302,)\n"
     ]
    }
   ],
   "source": [
    "print('X_test shape:',X_test.shape,'\\n','y_test shape:',y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AdaBoostRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    " 'n_estimators': [50, 100],\n",
    " 'learning_rate' : [0.01,0.05,0.1,0.3,1],\n",
    " 'loss' : ['linear', 'square', 'exponential']\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 4493.107969999313\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "ada_grid_search = GridSearchCV(model,parameters,cv = 3)\n",
    "ada_grid_search_fit = ada_grid_search.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print('Time:',end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.01, 'loss': 'exponential', 'n_estimators': 50}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_grid_search_fit.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='exponential',\n",
       "         n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_grid_search_fit.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43120006350478934\n"
     ]
    }
   ],
   "source": [
    "print(ada_grid_search_fit.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 64.80776596069336\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "regessor = AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='exponential',\n",
    "         n_estimators=50, random_state=None)\n",
    "regessor_fit = regessor.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print('Time:',end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = regessor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_confidence = pd.DataFrame({\"predicted_confidence\": result})\n",
    "test_typo =  pd.DataFrame({\"typo\": np.array(test_words['Typo'])})\n",
    "test_truth = pd.DataFrame({\"truth\": np.array(test_words['Truth'])})\n",
    "test_candidate = pd.DataFrame({\"candidate\": np.array(test_words['Candidate'])})\n",
    "label = pd.DataFrame({\"label\": np.array(y_test)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>typo</th>\n",
       "      <th>truth</th>\n",
       "      <th>candidate</th>\n",
       "      <th>predicted_confidence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cm</td>\n",
       "      <td>cma</td>\n",
       "      <td>a</td>\n",
       "      <td>0.000915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cm</td>\n",
       "      <td>cma</td>\n",
       "      <td>aa</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cm</td>\n",
       "      <td>cma</td>\n",
       "      <td>aach</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cm</td>\n",
       "      <td>cma</td>\n",
       "      <td>aad</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cm</td>\n",
       "      <td>cma</td>\n",
       "      <td>aai</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cm</td>\n",
       "      <td>cma</td>\n",
       "      <td>aam</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cm</td>\n",
       "      <td>cma</td>\n",
       "      <td>aar</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cm</td>\n",
       "      <td>cma</td>\n",
       "      <td>ab</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cm</td>\n",
       "      <td>cma</td>\n",
       "      <td>abc</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cm</td>\n",
       "      <td>cma</td>\n",
       "      <td>abcs</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cm</td>\n",
       "      <td>cma</td>\n",
       "      <td>ac</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cm</td>\n",
       "      <td>cma</td>\n",
       "      <td>aca</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cm</td>\n",
       "      <td>cma</td>\n",
       "      <td>acaa</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cm</td>\n",
       "      <td>cma</td>\n",
       "      <td>acc</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cm</td>\n",
       "      <td>cma</td>\n",
       "      <td>ach</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cm</td>\n",
       "      <td>cma</td>\n",
       "      <td>acic</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cm</td>\n",
       "      <td>cma</td>\n",
       "      <td>acid</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cm</td>\n",
       "      <td>cma</td>\n",
       "      <td>acit</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cm</td>\n",
       "      <td>cma</td>\n",
       "      <td>acm</td>\n",
       "      <td>0.083100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cm</td>\n",
       "      <td>cma</td>\n",
       "      <td>acma</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   typo truth candidate  predicted_confidence  label\n",
       "0    cm   cma         a              0.000915      0\n",
       "1    cm   cma        aa              0.000872      0\n",
       "2    cm   cma      aach              0.000872      0\n",
       "3    cm   cma       aad              0.000872      0\n",
       "4    cm   cma       aai              0.000872      0\n",
       "5    cm   cma       aam              0.000872      0\n",
       "6    cm   cma       aar              0.000872      0\n",
       "7    cm   cma        ab              0.000872      0\n",
       "8    cm   cma       abc              0.000872      0\n",
       "9    cm   cma      abcs              0.000872      0\n",
       "10   cm   cma        ac              0.000872      0\n",
       "11   cm   cma       aca              0.000872      0\n",
       "12   cm   cma      acaa              0.000872      0\n",
       "13   cm   cma       acc              0.000872      0\n",
       "14   cm   cma       ach              0.000872      0\n",
       "15   cm   cma      acic              0.000872      0\n",
       "16   cm   cma      acid              0.000872      0\n",
       "17   cm   cma      acit              0.000872      0\n",
       "18   cm   cma       acm              0.083100      0\n",
       "19   cm   cma      acma              0.000872      0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsorted_test_final_output = pd.concat([test_typo, test_truth, test_candidate, predicted_confidence, label], axis=1)\n",
    "unsorted_test_final_output.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define files path\n",
    "tess_dir = \"../data/tesseract/\"\n",
    "ground_dir = \"../data/ground_truth_trimmed/\"\n",
    "file_name = os.listdir(tess_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "373.4526343799894"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Avreage Number of Candidates \n",
    "feature_output.shape[0]/feature_output[feature_output.Label==1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top_n candidates\n",
    "candidate_10 = unsorted_test_final_output.groupby(\"typo\").apply(lambda x: x.nlargest(10,columns = 'predicted_confidence'))\n",
    "candidate_5 = unsorted_test_final_output.groupby(\"typo\").apply(lambda x: x.nlargest(5,columns = 'predicted_confidence'))\n",
    "candidate_3 = unsorted_test_final_output.groupby(\"typo\").apply(lambda x: x.nlargest(3,columns = 'predicted_confidence'))\n",
    "candidate_1 = unsorted_test_final_output.groupby(\"typo\").apply(lambda x: x.nlargest(1,columns = 'predicted_confidence'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>typo</th>\n",
       "      <th>truth</th>\n",
       "      <th>candidate</th>\n",
       "      <th>predicted_confidence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>141602</th>\n",
       "      <td>acrsv</td>\n",
       "      <td>acrs</td>\n",
       "      <td>acrs</td>\n",
       "      <td>0.408900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141598</th>\n",
       "      <td>acrsv</td>\n",
       "      <td>acrs</td>\n",
       "      <td>acr</td>\n",
       "      <td>0.083100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141601</th>\n",
       "      <td>acrsv</td>\n",
       "      <td>acrs</td>\n",
       "      <td>across</td>\n",
       "      <td>0.083100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141599</th>\n",
       "      <td>acrsv</td>\n",
       "      <td>acrs</td>\n",
       "      <td>acra</td>\n",
       "      <td>0.029477</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141600</th>\n",
       "      <td>acrsv</td>\n",
       "      <td>acrs</td>\n",
       "      <td>acre</td>\n",
       "      <td>0.029477</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141603</th>\n",
       "      <td>acrsv</td>\n",
       "      <td>acrs</td>\n",
       "      <td>acs</td>\n",
       "      <td>0.024112</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141605</th>\n",
       "      <td>acrsv</td>\n",
       "      <td>acrs</td>\n",
       "      <td>act</td>\n",
       "      <td>0.000915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141623</th>\n",
       "      <td>acrsv</td>\n",
       "      <td>acrs</td>\n",
       "      <td>air</td>\n",
       "      <td>0.000915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141627</th>\n",
       "      <td>acrsv</td>\n",
       "      <td>acrs</td>\n",
       "      <td>also</td>\n",
       "      <td>0.000915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141648</th>\n",
       "      <td>acrsv</td>\n",
       "      <td>acrs</td>\n",
       "      <td>are</td>\n",
       "      <td>0.000915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         typo truth candidate  predicted_confidence  label\n",
       "141602  acrsv  acrs      acrs              0.408900      1\n",
       "141598  acrsv  acrs       acr              0.083100      0\n",
       "141601  acrsv  acrs    across              0.083100      0\n",
       "141599  acrsv  acrs      acra              0.029477      0\n",
       "141600  acrsv  acrs      acre              0.029477      0\n",
       "141603  acrsv  acrs       acs              0.024112      0\n",
       "141605  acrsv  acrs       act              0.000915      0\n",
       "141623  acrsv  acrs       air              0.000915      0\n",
       "141627  acrsv  acrs      also              0.000915      0\n",
       "141648  acrsv  acrs       are              0.000915      0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_10.loc['acrsv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>71.41%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>86.33%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>89.09%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>91.02%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   top precision\n",
       "0    1    71.41%\n",
       "1    3    86.33%\n",
       "2    5    89.09%\n",
       "3   10    91.02%"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Top_n candidates wordwise precision\n",
    "total_typo = sum(y_test==1)\n",
    "top_10= \"{0:.2%}\".format(candidate_10[candidate_10.label==1].shape[0]/total_typo)\n",
    "top_5= \"{0:.2%}\".format(candidate_5[candidate_5.label==1].shape[0]/total_typo)\n",
    "top_3= \"{0:.2%}\".format(candidate_3[candidate_3.label==1].shape[0]/total_typo)\n",
    "top_1= \"{0:.2%}\".format(candidate_1[candidate_1.label==1].shape[0]/total_typo)\n",
    "\n",
    "top = pd.DataFrame({\"top\": np.array([1,3,5,10])})\n",
    "precision = pd.DataFrame({\"precision\": np.array([top_1, top_3, top_5, top_10])})\n",
    "pd.concat([top, precision], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = regessor.predict(X[X.columns[3:6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_confidence = pd.DataFrame({\"predicted_confidence\": pred})\n",
    "test_typo =  pd.DataFrame({\"typo\": X['Typo']})\n",
    "test_truth = pd.DataFrame({\"truth\": X['Truth']})\n",
    "test_candidate = pd.DataFrame({\"candidate\": X['Candidate']})\n",
    "label = pd.DataFrame({\"label\": y})\n",
    "unsorted_test_final_output = pd.concat([test_typo, test_truth, test_candidate, predicted_confidence, label], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_1 = unsorted_test_final_output.groupby(\"typo\").apply(lambda x: x.nlargest(1,columns = 'predicted_confidence'))\n",
    "cand = candidate_1.candidate.values\n",
    "typo = candidate_1.typo.values\n",
    "cand_dict = dict(zip(typo, cand))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tess = []\n",
    "for s in tess:\n",
    "    if s in cand_dict:\n",
    "        new_tess.append(cand_dict[s])\n",
    "    else:\n",
    "        new_tess.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_tess = \" \".join(tess)\n",
    "char_new_tess = \" \".join(new_tess)\n",
    "char_truth = \" \".join(truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insect(sa,sb):\n",
    "    S_a = set(sa)\n",
    "    n=0\n",
    "    for s in S_a:\n",
    "        n += min(sa.count(s), sb.count(s))\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_word = insect(tess, truth)\n",
    "new_word = insect(new_tess, truth)\n",
    "old_char = insect(char_tess, char_truth)\n",
    "new_char = insect(char_new_tess, char_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Measure</th>\n",
       "      <th>Tesseract</th>\n",
       "      <th>Post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>word_wise_recall</td>\n",
       "      <td>0.049052</td>\n",
       "      <td>0.072612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>word_wise_precision</td>\n",
       "      <td>0.010380</td>\n",
       "      <td>0.015366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>character_wise_recall</td>\n",
       "      <td>0.921204</td>\n",
       "      <td>0.941488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>character_wise_precision</td>\n",
       "      <td>0.950425</td>\n",
       "      <td>0.969035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Measure  Tesseract      Post\n",
       "0          word_wise_recall   0.049052  0.072612\n",
       "1       word_wise_precision   0.010380  0.015366\n",
       "2     character_wise_recall   0.921204  0.941488\n",
       "3  character_wise_precision   0.950425  0.969035"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_word_tess = old_word/len(truth)\n",
    "precision_word_tess = old_word/len(tess)\n",
    "recall_word_post = new_word/len(truth)\n",
    "precision_word_post = new_word/len(new_tess)\n",
    "recall_char_tess = old_char/len(char_truth)\n",
    "precision_char_tess = old_char/len(char_tess)\n",
    "recall_char_post = new_char/len(char_truth)\n",
    "precision_char_post = new_char/len(char_new_tess)\n",
    "\n",
    "Measure = pd.DataFrame({\"Measure\": np.array(['word_wise_recall','word_wise_precision','character_wise_recall','character_wise_precision'])})\n",
    "Tesseract = pd.DataFrame({\"Tesseract\": np.array([recall_word_tess, precision_word_tess, recall_char_tess, precision_char_tess])})\n",
    "PostProcessing = pd.DataFrame({\"Post\": np.array([recall_word_post, precision_word_post, recall_char_post, precision_char_post])})\n",
    "pd.concat([Measure, Tesseract, PostProcessing], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
